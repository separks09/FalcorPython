{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phrase: #bigfoot\n",
      "Compound: -0.09806000000000001\n",
      "Positive: 0.01245\n",
      "Neutral: 0.9317500000000001\n",
      "Negative: 0.0558\n",
      "\n",
      "Phrase: #sasquatch\n",
      "Compound: 0.07217499999999999\n",
      "Positive: 0.0654\n",
      "Neutral: 0.8947500000000002\n",
      "Negative: 0.03985\n",
      "\n",
      "Phrase: #yeti\n",
      "Compound: 0.26721000000000006\n",
      "Positive: 0.11095\n",
      "Neutral: 0.87795\n",
      "Negative: 0.0111\n",
      "\n",
      "Phrase: #grassman\n",
      "Compound: 0.0\n",
      "Positive: 0.0\n",
      "Neutral: 1.0\n",
      "Negative: 0.0\n",
      "\n",
      "Phrase: #skunkape\n",
      "Compound: 0.6037\n",
      "Positive: 0.171\n",
      "Neutral: 0.829\n",
      "Negative: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Target hashtags\n",
    "target_tags_1 = [\"#bigfoot\", \"#sasquatch\", \"#yeti\", \"#grassman\", \"#skunkape\"]\n",
    "\n",
    "# Loop through timelines to find mentions\n",
    "for tag in target_tags_1:\n",
    "\n",
    "    # Variables for holding sentiments\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "\n",
    "    # Loop through the first 20 pages\n",
    "    for page in tweepy.Cursor(api.search, tag).pages(20):\n",
    "\n",
    "        # Get all tweets from home feed\n",
    "        page = page[0]\n",
    "        tweet = json.dumps(page._json, indent=3)\n",
    "        tweet = json.loads(tweet)\n",
    "        text = tweet['text']\n",
    "\n",
    "        # Run Vader Analysis on each tweet\n",
    "        compound = analyzer.polarity_scores(text)[\"compound\"]\n",
    "        pos = analyzer.polarity_scores(text)[\"pos\"]\n",
    "        neu = analyzer.polarity_scores(text)[\"neu\"]\n",
    "        neg = analyzer.polarity_scores(text)[\"neg\"]\n",
    "\n",
    "        # Add each value to the appropriate array\n",
    "        compound_list.append(compound)\n",
    "        positive_list.append(pos)\n",
    "        negative_list.append(neg)\n",
    "        neutral_list.append(neu)\n",
    "\n",
    "    # Print the Averages for each user\n",
    "    print(\"\")\n",
    "    print(\"Phrase: %s\" % tag)\n",
    "    print(\"Compound: %s\" % np.mean(compound_list))\n",
    "    print(\"Positive: %s\" % np.mean(positive_list))\n",
    "    print(\"Neutral: %s\" % np.mean(neutral_list))\n",
    "    print(\"Negative: %s\" % np.mean(negative_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phrase: #ufos\n",
      "Compound: 0.10349\n",
      "Positive: 0.05775\n",
      "Neutral: 0.92025\n",
      "Negative: 0.022050000000000004\n",
      "\n",
      "Phrase: #alien\n",
      "Compound: 0.035135000000000007\n",
      "Positive: 0.0382\n",
      "Neutral: 0.93025\n",
      "Negative: 0.0316\n",
      "\n",
      "Phrase: #ufosighting\n",
      "Compound: 0.010345\n",
      "Positive: 0.022799999999999997\n",
      "Neutral: 0.95915\n",
      "Negative: 0.018050000000000004\n",
      "\n",
      "Phrase: #extraterrestrial\n",
      "Compound: 0.0\n",
      "Positive: 0.0\n",
      "Neutral: 1.0\n",
      "Negative: 0.0\n",
      "\n",
      "Phrase: #flyingsaucer\n",
      "Compound: -0.006371428571428576\n",
      "Positive: 0.03314285714285714\n",
      "Neutral: 0.9347142857142856\n",
      "Negative: 0.03214285714285715\n"
     ]
    }
   ],
   "source": [
    "# Target hashtags\n",
    "target_tags_2 = [\"#ufos\", \"#alien\", \"#ufosighting\", \"#extraterrestrial\", \"#flyingsaucer\"]\n",
    "\n",
    "# Loop through timelines to find mentions\n",
    "for tag in target_tags_2:\n",
    "\n",
    "    # Variables for holding sentiments\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "\n",
    "    # Loop through the first 20 pages\n",
    "    for page in tweepy.Cursor(api.search, tag).pages(20):\n",
    "\n",
    "        # Get all tweets from home feed\n",
    "        page = page[0]\n",
    "        tweet = json.dumps(page._json, indent=3)\n",
    "        tweet = json.loads(tweet)\n",
    "        text = tweet['text']\n",
    "\n",
    "        # Run Vader Analysis on each tweet\n",
    "        compound = analyzer.polarity_scores(text)[\"compound\"]\n",
    "        pos = analyzer.polarity_scores(text)[\"pos\"]\n",
    "        neu = analyzer.polarity_scores(text)[\"neu\"]\n",
    "        neg = analyzer.polarity_scores(text)[\"neg\"]\n",
    "\n",
    "        # Add each value to the appropriate array\n",
    "        compound_list.append(compound)\n",
    "        positive_list.append(pos)\n",
    "        negative_list.append(neg)\n",
    "        neutral_list.append(neu)\n",
    "\n",
    "    # Print the Averages for each user\n",
    "    print(\"\")\n",
    "    print(\"Phrase: %s\" % tag)\n",
    "    print(\"Compound: %s\" % np.mean(compound_list))\n",
    "    print(\"Positive: %s\" % np.mean(positive_list))\n",
    "    print(\"Neutral: %s\" % np.mean(neutral_list))\n",
    "    print(\"Negative: %s\" % np.mean(negative_list))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
